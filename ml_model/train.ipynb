{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4036ddc",
   "metadata": {},
   "source": [
    "# Job Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f23ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from skillNer.general_params import SKILL_DB\n",
    "from skillNer.skill_extractor_class import SkillExtractor\n",
    "import docx2txt\n",
    "import PyPDF2\n",
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"\\[W008\\]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8434a0c3",
   "metadata": {},
   "source": [
    "Text Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50b36226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf_fitz(pdf_path):\n",
    "    text = \"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\") + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def extract_text_from_file(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    \n",
    "    if ext == \".pdf\":\n",
    "        try:\n",
    "            # Try PyPDF2 first\n",
    "            with open(file_path, \"rb\") as file:\n",
    "                reader = PyPDF2.PdfReader(file)\n",
    "                text = \"\"\n",
    "                for page in reader.pages:\n",
    "                    text += page.extract_text() or \"\"\n",
    "                if text.strip():\n",
    "                    return text\n",
    "                else:\n",
    "                    # fallback to PyMuPDF if empty\n",
    "                    return extract_text_from_pdf_fitz(file_path)\n",
    "        except Exception:\n",
    "            return extract_text_from_pdf_fitz(file_path)\n",
    "\n",
    "    elif ext == \".docx\":\n",
    "        try:\n",
    "            return docx2txt.process(file_path)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Failed to read DOCX: {e}\")\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type (.pdf/.docx only)\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eac394",
   "metadata": {},
   "source": [
    "print CV_Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f62d88",
   "metadata": {},
   "source": [
    "Custom Skill Loading and Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c292b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_skills_from_json(file_path=\"skills.json\"):\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "            return data.get(\"skills\", [])\n",
    "    except Exception as e:\n",
    "        print(f\" Could not load custom skills from JSON: {e}\")\n",
    "        return []\n",
    "\n",
    "def extract_skills_from_text(text, skill_keywords):\n",
    "    return [skill for skill in skill_keywords if skill.lower() in text.lower()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94494735",
   "metadata": {},
   "source": [
    "Initialize NLP and SkillExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d96dc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading full_matcher ...\n",
      "loading abv_matcher ...\n",
      "loading full_uni_matcher ...\n",
      "loading low_form_matcher ...\n",
      "loading token_matcher ...\n"
     ]
    }
   ],
   "source": [
    "# Load SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Initialize SkillExtractor\n",
    "try:\n",
    "    skill_extractor = SkillExtractor(nlp, SKILL_DB, PhraseMatcher)\n",
    "except Exception as e:\n",
    "    print(f\" Warning: Could not initialize SkillExtractor: {e}\")\n",
    "    skill_extractor = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556a2539",
   "metadata": {},
   "source": [
    "Load CV and Extract Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30400b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = input(\"Input path of your CV here (pdf or docx): \").strip()\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\" File not found: {file_path}\")\n",
    "\n",
    "try:\n",
    "    text = extract_text_from_file(file_path)\n",
    "except Exception as e:\n",
    "    print(f\" Error extracting text: {e}\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d31b27",
   "metadata": {},
   "source": [
    "Extract Skills Using SkillExtractor (NLP) and Custom Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad8d4100",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_skills = set()\n",
    "\n",
    "if skill_extractor:\n",
    "    try:\n",
    "        annotations = skill_extractor.annotate(text)\n",
    "        full_matches = annotations[\"results\"].get(\"full_matches\", [])\n",
    "        ngram_matches = annotations[\"results\"].get(\"ngram_scored\", [])\n",
    "\n",
    "        for match in full_matches + ngram_matches:\n",
    "            if \"doc_node_value\" in match:\n",
    "                nlp_skills.add(match[\"doc_node_value\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Error using SkillExtractor: {e}\")\n",
    "\n",
    "custom_skills_list = load_skills_from_json()\n",
    "keyword_skills = set(extract_skills_from_text(text, custom_skills_list))\n",
    "\n",
    "all_skills = nlp_skills.union(keyword_skills)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd88b85e",
   "metadata": {},
   "source": [
    "Print Extracted Skills Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d3c8b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Total Skills Extracted: 21\n",
      " NLP-based: ['teamwork', 'communication', 'languages khmer', 'm', 'microsoft office', 'english', 'com', 'creativity']\n",
      " Keyword-based: ['Teamwork', 'PowerPoint', 'English', 'R', 'AI', 'Word', 'Excel', 'Go', 'C', 'Khmer', 'D', 'Communication', 'Creativity']\n",
      "Combined: ['AI', 'C', 'Communication', 'Creativity', 'D', 'English', 'Excel', 'Go', 'Khmer', 'PowerPoint', 'R', 'Teamwork', 'Word', 'com', 'communication', 'creativity', 'english', 'languages khmer', 'microsoft office', 'teamwork']\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n Total Skills Extracted: {len(all_skills)}\")\n",
    "print(\" NLP-based:\", list(nlp_skills))\n",
    "print(\" Keyword-based:\", list(keyword_skills))\n",
    "# print(\" Combined:\", list(all_skills))\n",
    "# Normalize and deduplicate\n",
    "normalized_skills = set(skill.strip() for skill in all_skills)\n",
    "\n",
    "# Optionally convert back to list and sort\n",
    "unique_skills = sorted(normalized_skills)\n",
    "ignore = [\"c\", \"d\",\"m\", \"a\", \"b\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"n\",\"r\", \"o\", \"p\", \"q\",\"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"]\n",
    "\n",
    "# Remove ignored words from unique_skills\n",
    "unique_skills = [s for s in unique_skills if s not in ignore]\n",
    "print(\"Combined:\", list(unique_skills))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f66cb3",
   "metadata": {},
   "source": [
    "Load Job Dataset and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25ab7a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"camhr_cleaned_data.csv\")  \n",
    "df['job_text_lower'] = df['job_text'].fillna('').str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130ba1b4",
   "metadata": {},
   "source": [
    "Prepare CV Skills Text for TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41f91e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_skills_set = set(skill.lower() for skill in unique_skills)\n",
    "cv_text = ' '.join(cv_skills_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340385b7",
   "metadata": {},
   "source": [
    " TF-IDF Vectorization and Cosine Similarity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6be81202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a small, fast BERT model\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "771f7e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate embeddings\n",
    "cv_embedding = model.encode(cv_text, convert_to_tensor=True)\n",
    "# job_embeddings = model.encode(df['job_text'].tolist(), convert_to_tensor=True)\n",
    "try:\n",
    "    job_embeddings = torch.tensor(np.load(\"job_embeddings.npy\"))\n",
    "except FileNotFoundError:\n",
    "    job_embeddings = model.encode(df['job_text'].tolist(), convert_to_tensor=True, batch_size=32, show_progress_bar=True)\n",
    "    np.save(\"job_embeddings.npy\", job_embeddings.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "690f0cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0.321903\n",
      "1        0.243452\n",
      "2        0.263744\n",
      "3        0.360261\n",
      "4        0.343817\n",
      "           ...   \n",
      "20131    0.263744\n",
      "20132    0.210190\n",
      "20133    0.304808\n",
      "20134    0.362656\n",
      "20135    0.218359\n",
      "Name: bert_match_score, Length: 20136, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "#Compute cosine similarity\n",
    "cosine_scores = util.cos_sim(cv_embedding, job_embeddings)[0]\n",
    "df['bert_match_score'] = cosine_scores.cpu().numpy()\n",
    "print(df['bert_match_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9faeed64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0.020195\n",
      "1        0.049239\n",
      "2        0.014848\n",
      "3        0.015733\n",
      "4        0.050476\n",
      "           ...   \n",
      "20131    0.014848\n",
      "20132    0.006251\n",
      "20133    0.000000\n",
      "20134    0.014540\n",
      "20135    0.016296\n",
      "Name: tfidf_match_score, Length: 20136, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Compute TF-IDF similarity\n",
    "texts = df['job_text'].tolist() + [cv_text]\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
    "cv_vector = tfidf_matrix[-1]  # Last vector is for CV\n",
    "job_vectors = tfidf_matrix[:-1]  # All job vectors\n",
    "\n",
    "cosine_scores_tfidf = cosine_similarity(cv_vector, job_vectors).flatten()\n",
    "df['tfidf_match_score'] = cosine_scores_tfidf\n",
    "print(df['tfidf_match_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bde2a030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0.201219\n",
      "1        0.165767\n",
      "2        0.164186\n",
      "3        0.222449\n",
      "4        0.226481\n",
      "           ...   \n",
      "20131    0.164186\n",
      "20132    0.128614\n",
      "20133    0.182885\n",
      "20134    0.223410\n",
      "20135    0.137534\n",
      "Name: final_score, Length: 20136, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Combine BERT + TF-IDF\n",
    "# You can tune the weights (e.g., 0.6 for BERT, 0.4 for TF-IDF)\n",
    "df['final_score'] = 0.6 * df['bert_match_score'] + 0.4 * df['tfidf_match_score']\n",
    "print(df['final_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "608c07b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              {d, excel, c, ai, microsoft office, com, r}\n",
      "1        {d, excel, c, ai, microsoft office, com, word, r}\n",
      "2                              {d, c, english, com, r, go}\n",
      "3                              {d, c, english, com, r, go}\n",
      "4        {d, excel, teamwork, c, communication, english...\n",
      "                               ...                        \n",
      "20131                          {d, c, english, com, r, go}\n",
      "20132             {d, excel, c, communication, ai, com, r}\n",
      "20133                                   {d, c, com, r, go}\n",
      "20134         {d, excel, c, ai, english, com, word, r, go}\n",
      "20135                          {d, c, ai, english, com, r}\n",
      "Name: matched_skills, Length: 20136, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Compute matched skills\n",
    "\n",
    "def match_skills(job_text):\n",
    "    return {skill for skill in cv_skills_set if skill in job_text.lower()}\n",
    "\n",
    "df['matched_skills'] = df['job_text'].apply(match_skills)\n",
    "print(df['matched_skills'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e47b5c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort and filter matches\n",
    "df_sorted = df.sort_values(by='final_score', ascending=False)\n",
    "top_matches = df_sorted[df_sorted['final_score'] > 0.3]\n",
    "top_matches = top_matches.drop_duplicates(subset=['Company Name', 'Job Title'], keep='first')\n",
    "  # You can adjust threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a81bec",
   "metadata": {},
   "source": [
    "# Display Top 5 Job For User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab4a8702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>final_score</th>\n",
       "      <th>bert_match_score</th>\n",
       "      <th>tfidf_match_score</th>\n",
       "      <th>matched_skills</th>\n",
       "      <th>Link URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5799</th>\n",
       "      <td>Coordinator</td>\n",
       "      <td>Suosdey Works Pte., Ltd</td>\n",
       "      <td>0.445273</td>\n",
       "      <td>0.621728</td>\n",
       "      <td>0.180591</td>\n",
       "      <td>{d, excel, c, english, com, khmer, word, r}</td>\n",
       "      <td>https://www.camhr.com/a/job/10591233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13788</th>\n",
       "      <td>Academic Coordinator (Khmer Academic Program)</td>\n",
       "      <td>Westline School</td>\n",
       "      <td>0.431231</td>\n",
       "      <td>0.627288</td>\n",
       "      <td>0.137144</td>\n",
       "      <td>{d, excel, c, ai, khmer, word, r}</td>\n",
       "      <td>https://www.camhr.com/a/job/10587817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>Sales &amp; Marketing Admin</td>\n",
       "      <td>AQUALIFE CO., LTD.</td>\n",
       "      <td>0.419976</td>\n",
       "      <td>0.542577</td>\n",
       "      <td>0.236074</td>\n",
       "      <td>{d, excel, c, communication, microsoft office,...</td>\n",
       "      <td>https://www.camhr.com/a/job/10600546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11791</th>\n",
       "      <td>Vice Principal (Khmer Academic Program) at Wes...</td>\n",
       "      <td>Westline School</td>\n",
       "      <td>0.416121</td>\n",
       "      <td>0.618974</td>\n",
       "      <td>0.111840</td>\n",
       "      <td>{d, excel, c, ai, khmer, word, r}</td>\n",
       "      <td>https://www.camhr.com/a/job/10583765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17136</th>\n",
       "      <td>គ្រូភាសាខ្មែរ (មធ្យមសិក្សាបឋមភូមិ និងទុតិយភូមិ...</td>\n",
       "      <td>ក្រុមហ៊ុន ម៉េងលី ជេ. គួច អេឌ្យូខេសិន (Mengly J...</td>\n",
       "      <td>0.415006</td>\n",
       "      <td>0.643891</td>\n",
       "      <td>0.071678</td>\n",
       "      <td>{d, excel, c, ai, khmer, word, r}</td>\n",
       "      <td>https://www.camhr.com/a/job/10596672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Job Title  \\\n",
       "5799                                         Coordinator   \n",
       "13788      Academic Coordinator (Khmer Academic Program)   \n",
       "443                              Sales & Marketing Admin   \n",
       "11791  Vice Principal (Khmer Academic Program) at Wes...   \n",
       "17136  គ្រូភាសាខ្មែរ (មធ្យមសិក្សាបឋមភូមិ និងទុតិយភូមិ...   \n",
       "\n",
       "                                            Company Name  final_score  \\\n",
       "5799                             Suosdey Works Pte., Ltd     0.445273   \n",
       "13788                                    Westline School     0.431231   \n",
       "443                                   AQUALIFE CO., LTD.     0.419976   \n",
       "11791                                    Westline School     0.416121   \n",
       "17136  ក្រុមហ៊ុន ម៉េងលី ជេ. គួច អេឌ្យូខេសិន (Mengly J...     0.415006   \n",
       "\n",
       "       bert_match_score  tfidf_match_score  \\\n",
       "5799           0.621728           0.180591   \n",
       "13788          0.627288           0.137144   \n",
       "443            0.542577           0.236074   \n",
       "11791          0.618974           0.111840   \n",
       "17136          0.643891           0.071678   \n",
       "\n",
       "                                          matched_skills  \\\n",
       "5799         {d, excel, c, english, com, khmer, word, r}   \n",
       "13788                  {d, excel, c, ai, khmer, word, r}   \n",
       "443    {d, excel, c, communication, microsoft office,...   \n",
       "11791                  {d, excel, c, ai, khmer, word, r}   \n",
       "17136                  {d, excel, c, ai, khmer, word, r}   \n",
       "\n",
       "                                   Link URL  \n",
       "5799   https://www.camhr.com/a/job/10591233  \n",
       "13788  https://www.camhr.com/a/job/10587817  \n",
       "443    https://www.camhr.com/a/job/10600546  \n",
       "11791  https://www.camhr.com/a/job/10583765  \n",
       "17136  https://www.camhr.com/a/job/10596672  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Show top recommendations with scores and skills\n",
    "\n",
    "display(top_matches[['Job Title', 'Company Name', 'final_score', 'bert_match_score', 'tfidf_match_score', 'matched_skills', 'Link URL']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7d80ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# embeddings = np.load(\"job_embeddings.npy\")\n",
    "# df_embed = pd.DataFrame(embeddings)\n",
    "# df_embed.to_csv(\"job_embeddings_preview.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acc2ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = df['job_text_lower'].tolist() + [cv_text]\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "\n",
    "# cv_vector = tfidf_matrix[-1]\n",
    "# job_vectors = tfidf_matrix[:-1]\n",
    "\n",
    "# cosine_similarities = cosine_similarity(cv_vector, job_vectors).flatten()\n",
    "# df['match_score'] = cosine_similarities\n",
    "\n",
    "# print(df['match_score'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ba23e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.xlabel('Feature Index')\n",
    "# plt.ylabel('TF-IDF Value')\n",
    "\n",
    "# # # Plot the first job vector and the CV vector\n",
    "# # plt.plot(job_vectors.toarray()[0], label='First Job Vector')\n",
    "# # plt.plot(cv_vector.toarray()[0], label='CV Vector')\n",
    "\n",
    "# plt.title('TF-IDF Comparison: Job vs CV')\n",
    "# plt.scatter(range(len(job_vectors.toarray()[0])), job_vectors.toarray()[0], label='First Job Vector', alpha=0.7)\n",
    "# plt.scatter(range(len(cv_vector.toarray()[0])), cv_vector.toarray()[0], label='CV Vector', alpha=0.7)\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3261d635",
   "metadata": {},
   "source": [
    " Matched Skills (Keyword Overlap) per Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f497c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def match_skills(text):\n",
    "#     return {skill for skill in cv_skills_set if skill in text}\n",
    "\n",
    "# df['matched_skills'] = df['job_text_lower'].apply(match_skills)\n",
    "\n",
    "\n",
    "# print(df['matched_skills'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3bb231",
   "metadata": {},
   "source": [
    "filter by experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5dcdec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# from dateutil import parser\n",
    "# from datetime import datetime\n",
    "\n",
    "# def extract_experience_ranges(file_path):\n",
    "#     # Match common date range formats\n",
    "#     patterns = [\n",
    "#         r'([A-Za-z]{3,9} \\d{4})\\s*[-–]\\s*(Present|Current|[A-Za-z]{3,9} \\d{4})',\n",
    "#         r'(\\d{4}-\\d{2})\\s*[-–]\\s*(Present|Current|\\d{4}-\\d{2})'\n",
    "#     ]\n",
    "\n",
    "#     total_months = 0\n",
    "#     for pattern in patterns:\n",
    "#         matches = re.findall(pattern, file_path)\n",
    "#         for start_str, end_str in matches:\n",
    "#             try:\n",
    "#                 start_date = parser.parse(start_str)\n",
    "#                 end_date = datetime.today() if end_str.lower() in ['present', 'current'] else parser.parse(end_str)\n",
    "#                 months = (end_date.year - start_date.year) * 12 + (end_date.month - start_date.month)\n",
    "#                 total_months += max(months, 0)\n",
    "#             except Exception as e:\n",
    "#                 continue\n",
    "\n",
    "#     return round(total_months / 12, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f18da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cv_text = \"Feb 2020 – Present\\nMar 2018 – Dec 2019\"\n",
    "# years_exp = extract_experience_ranges(cv_text)\n",
    "# print(\"Estimated total years of experience:\", years_exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8017dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# # Updated dataset with new categories\n",
    "# data = [\n",
    "#     (0, 'Entry-Level'),\n",
    "#     (1, 'Entry-Level'),\n",
    "#     (2, 'Junior'),\n",
    "#     (3, 'Junior'),\n",
    "#     (4, 'Mid-Level'),\n",
    "#     (5, 'Mid-Level'),\n",
    "#     (6, 'Mid-Level'),\n",
    "#     (7, 'Senior'),\n",
    "#     (8, 'Senior'),\n",
    "#     (10, 'Senior'),\n",
    "#     (15, 'Senior'),\n",
    "#     (20, 'Senior'),\n",
    "# ]\n",
    "\n",
    "# # Split into features and labels\n",
    "# X = [[years] for years, label in data]\n",
    "# y = [label for years, label in data]\n",
    "\n",
    "# # Train the model\n",
    "# model = DecisionTreeClassifier()\n",
    "# model.fit(X, y)\n",
    "\n",
    "# # Get user input\n",
    "# y_ex = years_exp\n",
    "\n",
    "# # Predict category\n",
    "# prediction = model.predict([[y_ex]])\n",
    "# print(\"You are categorized as:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddb5daa",
   "metadata": {},
   "source": [
    "# Display Top 5 Job For User"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ab7230",
   "metadata": {},
   "source": [
    "Sort and Deduplicate by Company, Show Top Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ff7265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert 'Year of Exp.' to numeric, coerce errors to NaN, then fill NaN with 0 for comparison\n",
    "# df['Year of Exp.'] = pd.to_numeric(df['Year of Exp.'], errors='coerce').fillna(0)\n",
    "\n",
    "# df_sorted = df.sort_values(by='match_score', ascending=False)\n",
    "\n",
    "# df_sorted = df_sorted[df_sorted['match_score'] > 0.1]  # Filter out low match scores\n",
    "# #df_sorted = df_sorted[(df_sorted['Year of Exp.'] <= y_ex)] #| (df_sorted['Year of Exp.'] < y_ex - 2)]\n",
    "# df_unique_companies = df_sorted.drop_duplicates(subset='Company Name', keep='first')\n",
    "# display(df_unique_companies[['Job Title', 'Company Name', 'Year of Exp.', 'Salary', 'matched_skills', 'match_score', 'Link URL']].head(5))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
